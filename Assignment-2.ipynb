{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python_defaultSpec_1599473466168",
      "display_name": "Python 3.8.5 64-bit"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ZYy9o0KL-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "e66289c0-8e4c-4331-cc35-c6b94807340a",
        "tags": []
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading collection 'popular'\n[nltk_data]    | \n[nltk_data]    | Downloading package cmudict to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\cmudict.zip.\n[nltk_data]    | Downloading package gazetteers to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\gazetteers.zip.\n[nltk_data]    | Downloading package genesis to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\genesis.zip.\n[nltk_data]    | Downloading package gutenberg to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\gutenberg.zip.\n[nltk_data]    | Downloading package inaugural to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\inaugural.zip.\n[nltk_data]    | Downloading package movie_reviews to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\movie_reviews.zip.\n[nltk_data]    | Downloading package names to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\names.zip.\n[nltk_data]    | Downloading package shakespeare to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\shakespeare.zip.\n[nltk_data]    | Downloading package stopwords to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\stopwords.zip.\n[nltk_data]    | Downloading package treebank to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\treebank.zip.\n[nltk_data]    | Downloading package twitter_samples to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\twitter_samples.zip.\n[nltk_data]    | Downloading package omw to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\omw.zip.\n[nltk_data]    | Downloading package wordnet to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\wordnet.zip.\n[nltk_data]    | Downloading package wordnet_ic to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\wordnet_ic.zip.\n[nltk_data]    | Downloading package words to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping corpora\\words.zip.\n[nltk_data]    | Downloading package maxent_ne_chunker to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping chunkers\\maxent_ne_chunker.zip.\n[nltk_data]    | Downloading package punkt to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping tokenizers\\punkt.zip.\n[nltk_data]    | Downloading package snowball_data to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    | Downloading package averaged_perceptron_tagger to\n[nltk_data]    |     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]    |   Unzipping taggers\\averaged_perceptron_tagger.zip.\n[nltk_data]    | \n[nltk_data]  Done downloading collection popular\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfm8GP1yKg30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "350e95b3-57f4-413d-8d69-6c703d574578",
        "tags": []
      },
      "source": [
        "#word tokenize\n",
        "from nltk.tokenize import word_tokenize as wt\n",
        "text = \"Lorem ipsum dolor sit amet consectetur adipisicing elit. Quae dicta provident reprehenderit. Iste eum omnis repellendus eos voluptas magnam consequuntur minima doloremque nam tempore voluptatibus tempora, nisi laborum, laboriosam blanditiis. Qui eos fugiat velit animi autem perferendis obcaecati architecto cupiditate repellendus. Facere expedita hic temporibus eius eum? Facilis, fuga mollitia.\"\n",
        "print(wt(text))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['Lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipisicing', 'elit', '.', 'Quae', 'dicta', 'provident', 'reprehenderit', '.', 'Iste', 'eum', 'omnis', 'repellendus', 'eos', 'voluptas', 'magnam', 'consequuntur', 'minima', 'doloremque', 'nam', 'tempore', 'voluptatibus', 'tempora', ',', 'nisi', 'laborum', ',', 'laboriosam', 'blanditiis', '.', 'Qui', 'eos', 'fugiat', 'velit', 'animi', 'autem', 'perferendis', 'obcaecati', 'architecto', 'cupiditate', 'repellendus', '.', 'Facere', 'expedita', 'hic', 'temporibus', 'eius', 'eum', '?', 'Facilis', ',', 'fuga', 'mollitia', '.']\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdDvz_jXKmvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d100f2d1-a2ba-4c45-91fe-ee19c6f8ca27",
        "tags": []
      },
      "source": [
        "# Tokenization of paragraphs/sentences\n",
        "import nltk\n",
        "\n",
        "\n",
        "paragraph = \"\"\" Lorem ipsum dolor sit amet consectetur adipisicing elit. Quae dicta provident reprehenderit. Iste eum omnis repellendus eos voluptas magnam consequuntur minima doloremque nam tempore voluptatibus tempora, nisi laborum, laboriosam blanditiis. Qui eos fugiat velit animi autem perferendis obcaecati architecto cupiditate repellendus. Facere expedita hic temporibus eius eum? Facilis, fuga mollitia. \"\"\"\n",
        "               \n",
        "# Tokenizing sentences\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "# Tokenizing words\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "print(sentences)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[' Lorem ipsum dolor sit amet consectetur adipisicing elit.', 'Quae dicta provident reprehenderit.', 'Iste eum omnis repellendus eos voluptas magnam consequuntur minima doloremque nam tempore voluptatibus tempora, nisi laborum, laboriosam blanditiis.', 'Qui eos fugiat velit animi autem perferendis obcaecati architecto cupiditate repellendus.', 'Facere expedita hic temporibus eius eum?', 'Facilis, fuga mollitia.']\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBHtCkMsKs7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0b3eb457-7f70-4af4-cfe3-4c71bac376bd",
        "tags": []
      },
      "source": [
        "#stop words\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\punit\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JggtYoXKtXC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f71ca180-9e15-49a0-e75e-c81d875a8bcd",
        "tags": []
      },
      "source": [
        "print(stopwords.words('english'))\n",
        "\n",
        "text = \" Lorem ipsum dolor sit amet consectetur adipisicing elit. Quae dicta provident reprehenderit. Iste eum omnis repellendus eos voluptas magnam consequuntur minima doloremque nam tempore voluptatibus tempora, nisi laborum, laboriosam blanditiis. Qui eos fugiat velit animi autem perferendis obcaecati architecto cupiditate repellendus. Facere expedita hic temporibus eius eum? Facilis, fuga mollitia. \"\n",
        "text_tokens = word_tokenize(text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "\n",
        "print(text_tokens)\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n['Lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipisicing', 'elit', '.', 'Quae', 'dicta', 'provident', 'reprehenderit', '.', 'Iste', 'eum', 'omnis', 'repellendus', 'eos', 'voluptas', 'magnam', 'consequuntur', 'minima', 'doloremque', 'nam', 'tempore', 'voluptatibus', 'tempora', ',', 'nisi', 'laborum', ',', 'laboriosam', 'blanditiis', '.', 'Qui', 'eos', 'fugiat', 'velit', 'animi', 'autem', 'perferendis', 'obcaecati', 'architecto', 'cupiditate', 'repellendus', '.', 'Facere', 'expedita', 'hic', 'temporibus', 'eius', 'eum', '?', 'Facilis', ',', 'fuga', 'mollitia', '.']\n['Lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur', 'adipisicing', 'elit', '.', 'Quae', 'dicta', 'provident', 'reprehenderit', '.', 'Iste', 'eum', 'omnis', 'repellendus', 'eos', 'voluptas', 'magnam', 'consequuntur', 'minima', 'doloremque', 'nam', 'tempore', 'voluptatibus', 'tempora', ',', 'nisi', 'laborum', ',', 'laboriosam', 'blanditiis', '.', 'Qui', 'eos', 'fugiat', 'velit', 'animi', 'autem', 'perferendis', 'obcaecati', 'architecto', 'cupiditate', 'repellendus', '.', 'Facere', 'expedita', 'hic', 'temporibus', 'eius', 'eum', '?', 'Facilis', ',', 'fuga', 'mollitia', '.']\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4lXmWVPKtdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b75d79b9-1782-4089-951f-8ac0340aab22",
        "tags": []
      },
      "source": [
        "#stemming\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "porterStemmer = PorterStemmer()\n",
        "\n",
        "sentence=\"Lorem ipsum dolor sit amet consectetur adipisicing elit. Quae dicta provident reprehenderit. Iste eum omnis repellendus eos voluptas.\"\n",
        "wordList = nltk.word_tokenize(sentence)\n",
        "\n",
        "stemWords = [porterStemmer.stem(word) for word in wordList]\n",
        "\n",
        "print(' '.join(stemWords))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "lorem ipsum dolor sit amet consectetur adipis elit . quae dicta provid reprehenderit . ist eum omni repellendu eo volupta .\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ7oXAizKtjG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "2dda3a23-3a96-4d4a-9b99-cc3cdc5493bf",
        "tags": []
      },
      "source": [
        "#word lemma\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"Lorem ipsum dolor sit amet consectetur adipisicing elit. Quae dicta provident reprehenderit. Iste eum omnis repellendus eos voluptas.\"\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words\n",
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Word                Lemma               \nLorem               Lorem               \nipsum               ipsum               \ndolor               dolor               \nsit                 sit                 \namet                amet                \nconsectetur         consectetur         \nadipisicing         adipisicing         \nelit                elit                \nQuae                Quae                \ndicta               dictum              \nprovident           provident           \nreprehenderit       reprehenderit       \nIste                Iste                \neum                 eum                 \nomnis               omnis               \nrepellendus         repellendus         \neos                 eos                 \nvoluptas            voluptas            \n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL-6xIdCKtcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "51dfd78d-1298-4895-aa7c-6139c93b36f9"
      },
      "source": [
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wnl = WordNetLemmatizer()\n",
        "txt = \"\"\"Lorem ipsum dolor sit amet consectetur adipisicing elit. Quae dicta provident reprehenderit. Iste eum omnis repellendus eos voluptas.\"\"\"\n",
        "[wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(txt))]\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Lorem',\n 'ipsum',\n 'dolor',\n 'sit',\n 'amet',\n 'consectetur',\n 'adipisicing',\n 'elit',\n '.',\n 'Quae',\n 'dictum',\n 'provident',\n 'reprehenderit',\n '.',\n 'Iste',\n 'eum',\n 'omnis',\n 'repellendus',\n 'eos',\n 'voluptas',\n '.']"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fde145o2KtWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "5783ebbf-c1be-48ab-d6aa-566a30cb4b59"
      },
      "source": [
        "# TreebankWordTokenizer\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "text = \"Lorem ipsum dolor sit amet consectetur adipisicing elit. Quae dicta provident reprehenderit. Iste eum omnis repellendus eos voluptas.\"\n",
        "TreebankWordTokenizer().tokenize(text)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['Lorem',\n 'ipsum',\n 'dolor',\n 'sit',\n 'amet',\n 'consectetur',\n 'adipisicing',\n 'elit.',\n 'Quae',\n 'dicta',\n 'provident',\n 'reprehenderit.',\n 'Iste',\n 'eum',\n 'omnis',\n 'repellendus',\n 'eos',\n 'voluptas',\n '.']"
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}